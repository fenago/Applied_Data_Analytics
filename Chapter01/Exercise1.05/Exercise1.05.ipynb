{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"01-explore-data.ipynb","provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Understanding the data\n\nIn this first part, we load the data and perform some initial exploration on it. The main goal of this step is to acquire some basic knowledge about the data, how the various features are distributed, if there are missing values in it and so on.","metadata":{"id":"OsjvyRyVU3_G","colab_type":"text"}},{"cell_type":"code","source":"### imports\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\n\n# load hourly data\nhourly_data = pd.read_csv('../data/hour.csv')","metadata":{"id":"_wmNcEoRU3_K","colab_type":"code","colab":{}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check data format, number of missing values in the data and general statistics:","metadata":{"id":"qDc53XA2U3_P","colab_type":"text"}},{"cell_type":"code","source":"# print some generic statistics about the data\nprint(f\"Shape of data: {hourly_data.shape}\")\nprint(f\"Number of missing values in the data: {hourly_data.isnull().sum().sum()}\")\n\n# get statistics on the numerical columns\nhourly_data.describe().T","metadata":{"id":"9QFrElsEU3_Q","colab_type":"code","colab":{},"outputId":"6fda5579-55de-478b-a00d-ede2cfecd346"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a copy of the original data\npreprocessed_data = hourly_data.copy()\n\n# tranform seasons\nseasons_mapping = {1: 'winter', 2: 'spring', 3: 'summer', 4: 'fall'}\npreprocessed_data['season'] = preprocessed_data['season'].apply(lambda x: seasons_mapping[x])\n\n# transform yr\nyr_mapping = {0: 2011, 1: 2012}\npreprocessed_data['yr'] = preprocessed_data['yr'].apply(lambda x: yr_mapping[x])\n\n# transform weekday\nweekday_mapping = {0: 'Sunday', 1: 'Monday', 2: 'Tuesday', 3: 'Wednesday', 4: 'Thursday', 5: 'Friday', 6: 'Saturday'}\npreprocessed_data['weekday'] = preprocessed_data['weekday'].apply(lambda x: weekday_mapping[x])\n\n# transform weathersit\nweather_mapping = {1: 'clear', 2: 'cloudy', 3: 'light_rain_snow', 4: 'heavy_rain_snow'}\npreprocessed_data['weathersit'] = preprocessed_data['weathersit'].apply(lambda x: weather_mapping[x]) \n\n# transorm hum and windspeed\npreprocessed_data['hum'] = preprocessed_data['hum']*100\npreprocessed_data['windspeed'] = preprocessed_data['windspeed']*67\n\n# visualize preprocessed columns\ncols = ['season', 'yr', 'weekday', 'weathersit', 'hum', 'windspeed']\npreprocessed_data[cols].sample(10, random_state=123)","metadata":{"id":"7gGtv-TzU3_W","colab_type":"code","colab":{},"outputId":"8a79860f-0a5c-435a-c84f-859bdebf07d2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Registered vs casual use analysis","metadata":{"id":"KG1KtmxEU3_Z","colab_type":"text"}},{"cell_type":"code","source":"# assert that total numer of rides is equal to the sum of registered and casual ones\nassert (preprocessed_data.casual + preprocessed_data.registered == preprocessed_data.cnt).all(), \\\n'Sum of casual and registered rides not equal to total number of rides'","metadata":{"id":"UqkzCcSgU3_a","colab_type":"code","colab":{}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot distributions of registered vs casual rides\nsns.distplot(preprocessed_data['registered'], label='registered')\nsns.distplot(preprocessed_data['casual'], label='casual')\nplt.legend()\nplt.xlabel('rides')\nplt.ylabel(\"frequency\")\nplt.title(\"Rides distributions\")\nplt.savefig('figs/rides_distributions.png', format='png')","metadata":{"id":"_Iaalx50U3_e","colab_type":"code","colab":{},"outputId":"dffb1468-42ba-4e31-b55e-24fb1191260f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot evolution of rides over time\nplot_data = preprocessed_data[['registered', 'casual', 'dteday']]\nax = plot_data.groupby('dteday').sum().plot(figsize=(10,6))\nax.set_xlabel(\"time\");\nax.set_ylabel(\"number of rides per day\");\n\nplt.savefig('figs/rides_daily.png', format='png')","metadata":{"id":"Dggr9hCUU3_h","colab_type":"code","colab":{},"outputId":"ab4dd60e-3770-406b-b599-cfc63ef36da9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create new dataframe with necessary for plotting columns, and \n# obtain number of rides per day, by grouping over each day\nplot_data = preprocessed_data[['registered', 'casual', 'dteday']]\nplot_data = plot_data.groupby('dteday').sum()\n\n# define window for computing the rolling mean and standard deviation\nwindow = 7\nrolling_means = plot_data.rolling(window).mean()\nrolling_deviations = plot_data.rolling(window).std()\n\n# create a plot of the series, where we first plot the series of rolling means, \n# then we color the zone between the series of rolling means \n# +- 2 rolling standard deviations\nax = rolling_means.plot(figsize=(10,6))\nax.fill_between(rolling_means.index, \\\n                rolling_means['registered'] + 2*rolling_deviations['registered'], \\\n                rolling_means['registered'] - 2*rolling_deviations['registered'], \\\n                alpha = 0.2)\nax.fill_between(rolling_means.index, \\\n                rolling_means['casual'] + 2*rolling_deviations['casual'], \\\n                rolling_means['casual'] - 2*rolling_deviations['casual'], \\\n                alpha = 0.2)\nax.set_xlabel(\"time\");\nax.set_ylabel(\"number of rides per day\");\nplt.savefig('figs/rides_aggregated.png', format='png')","metadata":{"id":"O7FQzVXsU3_n","colab_type":"code","colab":{},"outputId":"fc4a0e32-9844-4521-b9d5-0362b059498a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select relevant columns\nplot_data = preprocessed_data[['hr', 'weekday', 'registered', 'casual']]\n\n# transform the data into a format, in number of entries are computed as count,\n# for each distinct hr, weekday and type (registered or casual)\nplot_data = plot_data.melt(id_vars=['hr', 'weekday'], var_name='type', value_name='count')\n\n# create FacetGrid object, in which a grid plot is produced. \n# As columns, we have the various days of the week,\n# as rows, the different types (registered and casual)\ngrid = sns.FacetGrid(plot_data, row='weekday', col='type', height=2.5,\\\n                     aspect=2.5, row_order=['Monday', 'Tuesday', \\\n                                            'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n\n# populate the FacetGrid with the specific plots\ngrid.map(sns.barplot, 'hr', 'count', alpha=0.5)\ngrid.savefig('figs/weekday_hour_distributions.png', format='png')","metadata":{"id":"4dbn7xG8U3_r","colab_type":"code","colab":{},"outputId":"87692c7b-cb9d-45f2-e818-d4c0db2aa3fa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select subset of the data\nplot_data = preprocessed_data[['hr', 'season', 'registered', 'casual']]\n\n# unpivot data from wide to long format\nplot_data = plot_data.melt(id_vars=['hr', 'season'], var_name='type', \\\n                           value_name='count')\n\n# define FacetGrid\ngrid = sns.FacetGrid(plot_data, row='season', \\\n                     col='type', height=2.5, aspect=2.5, \\\n                     row_order=['winter', 'spring', 'summer', 'fall'])\n\n# apply plotting function to each element in the grid\ngrid.map(sns.barplot, 'hr', 'count', alpha=0.5)\n\n# save figure\ngrid.savefig('figs/exercise_1_02_a.png', format='png')","metadata":{"id":"XTZ1VRjUU3_v","colab_type":"code","colab":{},"outputId":"0b350047-2f6e-4dfa-8a33-a84156ca9673"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_data = preprocessed_data[['weekday', 'season', 'registered', 'casual']]\nplot_data = plot_data.melt(id_vars=['weekday', 'season'], var_name='type', value_name='count')\n\ngrid = sns.FacetGrid(plot_data, row='season', col='type', height=2.5, aspect=2.5, \n                     row_order=['winter', 'spring', 'summer', 'fall'])\ngrid.map(sns.barplot, 'weekday', 'count', alpha=0.5, \n         order=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n\n# save figure\ngrid.savefig('figs/exercise_1_02_b.png', format='png')","metadata":{"id":"Ex9rqsOsU3_y","colab_type":"code","colab":{},"outputId":"dc70b067-4881-47ab-bb2d-bd8796a7243e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute population mean of registered rides\npopulation_mean = preprocessed_data.registered.mean()\n\n# get sample of the data (summer 2011)\nsample = preprocessed_data[(preprocessed_data.season == \"summer\") &\\\n                               (preprocessed_data.yr == 2011)].registered\n\n# perform t-test and compute p-value\nfrom scipy.stats import ttest_1samp\ntest_result = ttest_1samp(sample, population_mean)\nprint(f\"Test statistic: {test_result[0]:.03f}, p-value: {test_result[1]:.03f}\")\n\n# get sample as 5% of the full data\nimport random\nrandom.seed(111)\nsample_unbiased = preprocessed_data.registered.sample(frac=0.05)\ntest_result_unbiased = ttest_1samp(sample_unbiased, population_mean)\nprint(f\"Unbiased test statistic: {test_result_unbiased[0]:.03f}, p-value: {test_result_unbiased[1]:.03f}\")","metadata":{"id":"XzXEvDCaU3_2","colab_type":"code","colab":{},"outputId":"92d70fef-cae0-4a29-8670-f891c1e78f92"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define mask, indicating if the day is weekend or work day\nweekend_days = ['Saturday', 'Sunday']\nweekend_mask = preprocessed_data.weekday.isin(weekend_days)\nworkingdays_mask = ~preprocessed_data.weekday.isin(weekend_days)\n\n# select registered rides for the weekend and working days\nweekend_data = preprocessed_data.registered[weekend_mask]\nworkingdays_data = preprocessed_data.registered[workingdays_mask]\n\n# perform ttest\nfrom scipy.stats import ttest_ind\ntest_res = ttest_ind(weekend_data, workingdays_data)\nprint(f\"Statistic value: {test_res[0]:.03f}, p-value: {test_res[1]:.03f}\")\n\n# plot distributions of registered rides for working vs weekend days\nsns.distplot(weekend_data, label='weekend days')\nsns.distplot(workingdays_data, label='working days')\nplt.legend()\nplt.xlabel('rides')\nplt.ylabel('frequency')\nplt.title(\"Registered rides distributions\")\nplt.savefig('figs/exercise_1_04_a.png', format='png')","metadata":{"id":"KhUyw3fnU3_5","colab_type":"code","colab":{},"outputId":"b526654e-0da9-461e-a5f0-aca11edfea99"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select casual rides for the weekend and working days\nweekend_data = preprocessed_data.casual[weekend_mask]\nworkingdays_data = preprocessed_data.casual[workingdays_mask]\n\n# perform ttest\ntest_res = ttest_ind(weekend_data, workingdays_data)\nprint(f\"Statistic value: {test_res[0]:.03f}, p-value: {test_res[1]:.03f}\")\n\n# plot distributions of casual rides for working vs weekend days\nsns.distplot(weekend_data, label='weekend days')\nsns.distplot(workingdays_data, label='working days')\nplt.legend()\nplt.xlabel('rides')\nplt.ylabel('frequency')\nplt.title(\"Casual rides distributions\")\nplt.savefig('figs/exercise_1_04_b.png', format='png')","metadata":{"id":"VWjmoFniU3_8","colab_type":"code","colab":{},"outputId":"6bfb9d8a-b359-4590-9c8b-c50f118e4046"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis of weather related features","metadata":{"id":"55XrZ6oSU4AA","colab_type":"text"}},{"cell_type":"code","source":"def plot_correlations(data, col):\n    # get correlation between col and registered rides\n    corr_r = np.corrcoef(data[col], data[\"registered\"])[0,1]\n    ax = sns.regplot(x=col, y=\"registered\", data=data, scatter_kws={\"alpha\":0.05}, \n                     label=f\"Registered rides (correlation: {corr_r:.3f})\")\n    \n    # get correlation between col and casual rides\n    corr_c = np.corrcoef(data[col], data[\"casual\"])[0,1]\n    ax = sns.regplot(x=col, y='casual', data=data, scatter_kws={\"alpha\":0.05}, \n                    label=f\"Casual rides (correlation: {corr_c:.3f})\")\n    \n    #adjust legend alpha\n    legend = ax.legend()\n    for lh in legend.legendHandles: \n        lh.set_alpha(0.5)\n        \n    ax.set_ylabel(\"rides\")\n    ax.set_title(f\"Correlation between rides and {col}\")\n    return ax","metadata":{"id":"nVxH1J-FU4AB","colab_type":"code","colab":{}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = plot_correlations(preprocessed_data, 'temp')\nplt.savefig('figs/correlation_temp.png', format='png')","metadata":{"id":"kPCKWQW_U4AD","colab_type":"code","colab":{},"outputId":"7445c2d0-5e60-48a4-ec70-15487b693530"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = plot_correlations(preprocessed_data, 'atemp')\nplt.savefig('figs/correlation_atemp.png', format='png')","metadata":{"id":"52-MlxvpU4AG","colab_type":"code","colab":{},"outputId":"a6fb25e6-24e5-478c-d91a-db2ef82c67c7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = plot_correlations(preprocessed_data, 'hum')\nplt.savefig('figs/correlation_hum.png', format='png')","metadata":{"id":"wj5QRxJzU4AI","colab_type":"code","colab":{},"outputId":"5ab0995c-e1db-48ef-98e2-049d26cd4296"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = plot_correlations(preprocessed_data, 'windspeed')\nplt.savefig('figs/correlation_windspeed.png', format='png')","metadata":{"id":"_VRifXe3U4AL","colab_type":"code","colab":{},"outputId":"fa1d434d-f09f-4178-a8e1-f03fa75e4de4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Exercise 1.05: Evaluating Difference between Pearson and Spearman correlation","metadata":{"id":"faLwgey1X_w6","colab_type":"text"}},{"cell_type":"code","source":"from scipy.stats import pearsonr, spearmanr\n\n# define random variables\nx = np.linspace(0,5, 100)\ny_lin = 0.5*x + 0.1*np.random.randn(100)\ny_mon = np.exp(x) + 0.1*np.random.randn(100)\n\n# compute correlations\ncorr_lin_pearson = pearsonr(x, y_lin)[0]\ncorr_lin_spearman = spearmanr(x, y_lin)[0]\ncorr_mon_pearson = pearsonr(x, y_mon)[0]\ncorr_mon_spearman = spearmanr(x, y_mon)[0]\n\n# visualize variables\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\nax1.scatter(x, y_lin)\nax1.set_title(f\"Linear relationship\\n Pearson: {corr_lin_pearson:.3f}, Spearman: {corr_lin_spearman:.3f}\")\nax2.scatter(x, y_mon)\nax2.set_title(f\"Monotonic relationship\\n Pearson: {corr_mon_pearson:.3f}, Spearman: {corr_mon_spearman:.3f}\")\nfig.savefig('figs/exercise_1_05.png', format='png')","metadata":{"id":"_kI3pfOTU4AQ","colab_type":"code","colab":{},"outputId":"6bf060f5-8041-4be7-8767-62f31834b07d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define function for computing correlations\ndef compute_correlations(data, col):\n    pearson_reg = pearsonr(data[col], data[\"registered\"])[0]\n    pearson_cas = pearsonr(data[col], data[\"casual\"])[0]\n    spearman_reg = spearmanr(data[col], data[\"registered\"])[0]\n    spearman_cas = spearmanr(data[col], data[\"casual\"])[0]\n\n    return pd.Series({\"Pearson (registered)\": pearson_reg, \n                      \"Spearman (registered)\": spearman_reg,\n                      \"Pearson (casual)\": pearson_cas, \n                      \"Spearman (casual)\": spearman_cas})\n\n# compute correlation measures between different features\ncols = [\"temp\", \"atemp\", \"hum\", \"windspeed\"]\ncorr_data = pd.DataFrame(index=[\"Pearson (registered)\", \"Spearman (registered)\", \"Pearson (casual)\", \"Spearman (casual)\"])\n\nfor col in cols:\n    corr_data[col] =  compute_correlations(preprocessed_data, col)\n    \ncorr_data.T","metadata":{"id":"s3v1zHhnU4AV","colab_type":"code","colab":{},"outputId":"48e6c67a-b21b-4e8e-8c9e-16a54689cf57"},"execution_count":null,"outputs":[]}]}