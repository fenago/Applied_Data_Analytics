{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Understanding the data\n\nIn this first part, we load the data and perform some initial exploration on it. The main goal of this step is to acquire some basic knowledge about the data, how the various features are distributed, if there are missing values in it and so on.","metadata":{}},{"cell_type":"code","source":"### imports\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\n\n# load hourly data\nhourly_data = pd.read_csv('../data/hour.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check data format, number of missing values in the data and general statistics:","metadata":{}},{"cell_type":"code","source":"# print some generic statistics about the data\nprint(f\"Shape of data: {hourly_data.shape}\")\nprint(f\"Number of missing values in the data: {hourly_data.isnull().sum().sum()}\")\n\n# get statistics on the numerical columns\nhourly_data.describe().T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exercise 1.01:  Preprocessing temporal and weather features","metadata":{}},{"cell_type":"code","source":"# create a copy of the original data\npreprocessed_data = hourly_data.copy()\n\n# tranform seasons\nseasons_mapping = {1: 'winter', 2: 'spring', 3: 'summer', 4: 'fall'}\npreprocessed_data['season'] = preprocessed_data['season'].apply(lambda x: seasons_mapping[x])\n\n# transform yr\nyr_mapping = {0: 2011, 1: 2012}\npreprocessed_data['yr'] = preprocessed_data['yr'].apply(lambda x: yr_mapping[x])\n\n# transform weekday\nweekday_mapping = {0: 'Sunday', 1: 'Monday', 2: 'Tuesday', 3: 'Wednesday', 4: 'Thursday', 5: 'Friday', 6: 'Saturday'}\npreprocessed_data['weekday'] = preprocessed_data['weekday'].apply(lambda x: weekday_mapping[x])\n\n# transform weathersit\nweather_mapping = {1: 'clear', 2: 'cloudy', 3: 'light_rain_snow', 4: 'heavy_rain_snow'}\npreprocessed_data['weathersit'] = preprocessed_data['weathersit'].apply(lambda x: weather_mapping[x]) \n\n# transorm hum and windspeed\npreprocessed_data['hum'] = preprocessed_data['hum']*100\npreprocessed_data['windspeed'] = preprocessed_data['windspeed']*67\n\n# visualize preprocessed columns\ncols = ['season', 'yr', 'weekday', 'weathersit', 'hum', 'windspeed']\npreprocessed_data[cols].sample(10, random_state=123)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Registered vs casual use analysis","metadata":{}},{"cell_type":"code","source":"# assert that total numer of rides is equal to the sum of registered and casual ones\nassert (preprocessed_data.casual + preprocessed_data.registered == preprocessed_data.cnt).all(), \\\n'Sum of casual and registered rides not equal to total number of rides'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot distributions of registered vs casual rides\nsns.distplot(preprocessed_data['registered'], label='registered')\nsns.distplot(preprocessed_data['casual'], label='casual')\nplt.legend()\nplt.xlabel('rides')\nplt.ylabel(\"frequency\")\nplt.title(\"Rides distributions\")\nplt.savefig('figs/rides_distributions.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot evolution of rides over time\nplot_data = preprocessed_data[['registered', 'casual', 'dteday']]\nax = plot_data.groupby('dteday').sum().plot(figsize=(10,6))\nax.set_xlabel(\"time\");\nax.set_ylabel(\"number of rides per day\");\n\nplt.savefig('figs/rides_daily.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create new dataframe with necessary for plotting columns, and \n# obtain number of rides per day, by grouping over each day\nplot_data = preprocessed_data[['registered', 'casual', 'dteday']]\nplot_data = plot_data.groupby('dteday').sum()\n\n# define window for computing the rolling mean and standard deviation\nwindow = 7\nrolling_means = plot_data.rolling(window).mean()\nrolling_deviations = plot_data.rolling(window).std()\n\n# create a plot of the series, where we first plot the series of rolling means, \n# then we color the zone between the series of rolling means \n# +- 2 rolling standard deviations\nax = rolling_means.plot(figsize=(10,6))\nax.fill_between(rolling_means.index, \\\n                rolling_means['registered'] + 2*rolling_deviations['registered'], \\\n                rolling_means['registered'] - 2*rolling_deviations['registered'], \\\n                alpha = 0.2)\nax.fill_between(rolling_means.index, \\\n                rolling_means['casual'] + 2*rolling_deviations['casual'], \\\n                rolling_means['casual'] - 2*rolling_deviations['casual'], \\\n                alpha = 0.2)\nax.set_xlabel(\"time\");\nax.set_ylabel(\"number of rides per day\");\nplt.savefig('figs/rides_aggregated.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select relevant columns\nplot_data = preprocessed_data[['hr', 'weekday', 'registered', 'casual']]\n\n# transform the data into a format, in number of entries are computed as count,\n# for each distinct hr, weekday and type (registered or casual)\nplot_data = plot_data.melt(id_vars=['hr', 'weekday'], var_name='type', value_name='count')\n\n# create FacetGrid object, in which a grid plot is produced. \n# As columns, we have the various days of the week,\n# as rows, the different types (registered and casual)\ngrid = sns.FacetGrid(plot_data, row='weekday', col='type', height=2.5,\\\n                     aspect=2.5, row_order=['Monday', 'Tuesday', \\\n                                            'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n\n# populate the FacetGrid with the specific plots\ngrid.map(sns.barplot, 'hr', 'count', alpha=0.5)\ngrid.savefig('figs/weekday_hour_distributions.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exercise 1.02: Analyzing season impact on rides","metadata":{}},{"cell_type":"code","source":"# select subset of the data\nplot_data = preprocessed_data[['hr', 'season', 'registered', 'casual']]\n\n# unpivot data from wide to long format\nplot_data = plot_data.melt(id_vars=['hr', 'season'], var_name='type', \\\n                           value_name='count')\n\n# define FacetGrid\ngrid = sns.FacetGrid(plot_data, row='season', \\\n                     col='type', height=2.5, aspect=2.5, \\\n                     row_order=['winter', 'spring', 'summer', 'fall'])\n\n# apply plotting function to each element in the grid\ngrid.map(sns.barplot, 'hr', 'count', alpha=0.5)\n\n# save figure\ngrid.savefig('figs/exercise_1_02_a.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_data = preprocessed_data[['weekday', 'season', 'registered', 'casual']]\nplot_data = plot_data.melt(id_vars=['weekday', 'season'], var_name='type', value_name='count')\n\ngrid = sns.FacetGrid(plot_data, row='season', col='type', height=2.5, aspect=2.5, \n                     row_order=['winter', 'spring', 'summer', 'fall'])\ngrid.map(sns.barplot, 'weekday', 'count', alpha=0.5, \n         order=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n\n# save figure\ngrid.savefig('figs/exercise_1_02_b.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exercise 1.03: Estimating average registered rides","metadata":{}},{"cell_type":"code","source":"# compute population mean of registered rides\npopulation_mean = preprocessed_data.registered.mean()\n\n# get sample of the data (summer 2011)\nsample = preprocessed_data[(preprocessed_data.season == \"summer\") &\\\n                               (preprocessed_data.yr == 2011)].registered\n\n# perform t-test and compute p-value\nfrom scipy.stats import ttest_1samp\ntest_result = ttest_1samp(sample, population_mean)\nprint(f\"Test statistic: {test_result[0]:.03f}, p-value: {test_result[1]:.03f}\")\n\n# get sample as 5% of the full data\nimport random\nrandom.seed(111)\nsample_unbiased = preprocessed_data.registered.sample(frac=0.05)\ntest_result_unbiased = ttest_1samp(sample_unbiased, population_mean)\nprint(f\"Unbiased test statistic: {test_result_unbiased[0]:.03f}, p-value: {test_result_unbiased[1]:.03f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exercise 1.04: Hypothesis testing on registered rides","metadata":{}},{"cell_type":"code","source":"# define mask, indicating if the day is weekend or work day\nweekend_days = ['Saturday', 'Sunday']\nweekend_mask = preprocessed_data.weekday.isin(weekend_days)\nworkingdays_mask = ~preprocessed_data.weekday.isin(weekend_days)\n\n# select registered rides for the weekend and working days\nweekend_data = preprocessed_data.registered[weekend_mask]\nworkingdays_data = preprocessed_data.registered[workingdays_mask]\n\n# perform ttest\nfrom scipy.stats import ttest_ind\ntest_res = ttest_ind(weekend_data, workingdays_data)\nprint(f\"Statistic value: {test_res[0]:.03f}, p-value: {test_res[1]:.03f}\")\n\n# plot distributions of registered rides for working vs weekend days\nsns.distplot(weekend_data, label='weekend days')\nsns.distplot(workingdays_data, label='working days')\nplt.legend()\nplt.xlabel('rides')\nplt.ylabel('frequency')\nplt.title(\"Registered rides distributions\")\nplt.savefig('figs/exercise_1_04_a.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select casual rides for the weekend and working days\nweekend_data = preprocessed_data.casual[weekend_mask]\nworkingdays_data = preprocessed_data.casual[workingdays_mask]\n\n# perform ttest\ntest_res = ttest_ind(weekend_data, workingdays_data)\nprint(f\"Statistic value: {test_res[0]:.03f}, p-value: {test_res[1]:.03f}\")\n\n# plot distributions of casual rides for working vs weekend days\nsns.distplot(weekend_data, label='weekend days')\nsns.distplot(workingdays_data, label='working days')\nplt.legend()\nplt.xlabel('rides')\nplt.ylabel('frequency')\nplt.title(\"Casual rides distributions\")\nplt.savefig('figs/exercise_1_04_b.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis of weather related features","metadata":{}},{"cell_type":"code","source":"def plot_correlations(data, col):\n    # get correlation between col and registered rides\n    corr_r = np.corrcoef(data[col], data[\"registered\"])[0,1]\n    ax = sns.regplot(x=col, y=\"registered\", data=data, scatter_kws={\"alpha\":0.05}, \n                     label=f\"Registered rides (correlation: {corr_r:.3f})\")\n    \n    # get correlation between col and casual rides\n    corr_c = np.corrcoef(data[col], data[\"casual\"])[0,1]\n    ax = sns.regplot(x=col, y='casual', data=data, scatter_kws={\"alpha\":0.05}, \n                    label=f\"Casual rides (correlation: {corr_c:.3f})\")\n    \n    #adjust legend alpha\n    legend = ax.legend()\n    for lh in legend.legendHandles: \n        lh.set_alpha(0.5)\n        \n    ax.set_ylabel(\"rides\")\n    ax.set_title(f\"Correlation between rides and {col}\")\n    return ax","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = plot_correlations(preprocessed_data, 'temp')\nplt.savefig('figs/correlation_temp.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = plot_correlations(preprocessed_data, 'atemp')\nplt.savefig('figs/correlation_atemp.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = plot_correlations(preprocessed_data, 'hum')\nplt.savefig('figs/correlation_hum.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = plot_correlations(preprocessed_data, 'windspeed')\nplt.savefig('figs/correlation_windspeed.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exercise 1.05: Difference between Pearson and Spearman correlations","metadata":{}},{"cell_type":"code","source":"from scipy.stats import pearsonr, spearmanr\n\n# define random variables\nx = np.linspace(0,5, 100)\ny_lin = 0.5*x + 0.1*np.random.randn(100)\ny_mon = np.exp(x) + 0.1*np.random.randn(100)\n\n# compute correlations\ncorr_lin_pearson = pearsonr(x, y_lin)[0]\ncorr_lin_spearman = spearmanr(x, y_lin)[0]\ncorr_mon_pearson = pearsonr(x, y_mon)[0]\ncorr_mon_spearman = spearmanr(x, y_mon)[0]\n\n# visualize variables\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\nax1.scatter(x, y_lin)\nax1.set_title(f\"Linear relationship\\n Pearson: {corr_lin_pearson:.3f}, Spearman: {corr_lin_spearman:.3f}\")\nax2.scatter(x, y_mon)\nax2.set_title(f\"Monotonic relationship\\n Pearson: {corr_mon_pearson:.3f}, Spearman: {corr_mon_spearman:.3f}\")\nfig.savefig('figs/exercise_1_05.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define function for computing correlations\ndef compute_correlations(data, col):\n    pearson_reg = pearsonr(data[col], data[\"registered\"])[0]\n    pearson_cas = pearsonr(data[col], data[\"casual\"])[0]\n    spearman_reg = spearmanr(data[col], data[\"registered\"])[0]\n    spearman_cas = spearmanr(data[col], data[\"casual\"])[0]\n\n    return pd.Series({\"Pearson (registered)\": pearson_reg, \n                      \"Spearman (registered)\": spearman_reg,\n                      \"Pearson (casual)\": pearson_cas, \n                      \"Spearman (casual)\": spearman_cas})\n\n# compute correlation measures between different features\ncols = [\"temp\", \"atemp\", \"hum\", \"windspeed\"]\ncorr_data = pd.DataFrame(index=[\"Pearson (registered)\", \"Spearman (registered)\", \"Pearson (casual)\", \"Spearman (casual)\"])\n\nfor col in cols:\n    corr_data[col] =  compute_correlations(preprocessed_data, col)\n    \ncorr_data.T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot correlation matrix\ncols = [\"temp\", \"atemp\", \"hum\", \"windspeed\", \"registered\", \"casual\"]\nplot_data = preprocessed_data[cols]\ncorr = plot_data.corr()\n\nfig = plt.figure(figsize=(10,8))\nplt.matshow(corr, fignum=fig.number)\nplt.xticks(range(len(plot_data.columns)), plot_data.columns)\nplt.yticks(range(len(plot_data.columns)), plot_data.columns)\nplt.colorbar()\nplt.ylim([5.5, -0.5])\nfig.savefig('figs/correlations.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Time series analysis","metadata":{}},{"cell_type":"code","source":"# get daily rides\ndaily_rides = preprocessed_data[[\"dteday\", \"registered\", \"casual\"]]\ndaily_rides = daily_rides.groupby(\"dteday\").sum()\n\n# convert index to DateTime object\ndaily_rides.index = pd.to_datetime(daily_rides.index)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define function for plotting rolling statistics and ADF test for time series\nfrom statsmodels.tsa.stattools import adfuller\n\ndef test_stationarity(ts, window=10, **kwargs):\n    # create dataframe for plotting\n    plot_data = pd.DataFrame(ts)\n    plot_data['rolling_mean'] = ts.rolling(window).mean()\n    plot_data['rolling_std'] = ts.rolling(window).std()\n\n    # compute p-value of Dickey-Fuller test\n    p_val = adfuller(ts)[1]\n\n    ax = plot_data.plot(**kwargs)\n    ax.set_title(f\"Dickey-Fuller p-value: {p_val:.3f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\ntest_stationarity(daily_rides[\"registered\"], figsize=(10, 8))\nplt.savefig('figs/daily_registered_original.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\ntest_stationarity(daily_rides[\"casual\"], figsize=(10, 8))\nplt.savefig('figs/daily_casual_original.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make time series stationary\nregistered = daily_rides[\"registered\"]\nregistered_ma = registered.rolling(10).mean()\nregistered_ma_diff = registered - registered_ma\nregistered_ma_diff.dropna(inplace=True)\n\ncasual = daily_rides[\"casual\"]\ncasual_ma = casual.rolling(10).mean()\ncasual_ma_diff = casual - casual_ma\ncasual_ma_diff.dropna(inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\ntest_stationarity(registered_ma_diff, figsize=(10, 8))\nplt.savefig('figs/daily_registered_ma_diff.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\ntest_stationarity(casual_ma_diff, figsize=(10, 8))\nplt.savefig('figs/daily_casual_ma_diff.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# subtract last value\nregistered = daily_rides[\"registered\"]\nregistered_diff = registered - registered.shift()\nregistered_diff.dropna(inplace=True)\n\ncasual = daily_rides[\"casual\"]\ncasual_diff = casual - casual.shift()\ncasual_diff.dropna(inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\ntest_stationarity(registered_diff, figsize=(10, 8))\nplt.savefig('figs/daily_registered_diff.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\ntest_stationarity(casual_diff, figsize=(10, 8))\nplt.savefig('figs/daily_casual_diff.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exercise 1.06: Time series decomposition in trend, seasonality and residuals","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\nregistered_decomposition = seasonal_decompose(daily_rides[\"registered\"])\ncasual_decomposition = seasonal_decompose(daily_rides[\"casual\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot decompositions\nregistered_plot = registered_decomposition.plot()\nregistered_plot.set_size_inches(10, 8)\n\ncasual_plot = casual_decomposition.plot()\ncasual_plot.set_size_inches(10, 8)\n\nregistered_plot.savefig('figs/registered_decomposition.png', format='png')\ncasual_plot.savefig('figs/casual_decomposition.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test residuals for stationarity\nplt.figure()\ntest_stationarity(registered_decomposition.resid.dropna(), figsize=(10, 8))\nplt.savefig('figs/registered_resid.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test residuals for stationarity\nplt.figure()\ntest_stationarity(casual_decomposition.resid.dropna(), figsize=(10, 8))\nplt.savefig('figs/casual_resid.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exercise 1.07: ACF and PACF","metadata":{}},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nfig, axes = plt.subplots(3, 3, figsize=(25, 12))\n\n# plot original series\noriginal = daily_rides[\"registered\"]\naxes[0,0].plot(original)\naxes[0,0].set_title(\"Original series\");\nplot_acf(original, ax=axes[0,1])\nplot_pacf(original, ax=axes[0,2])\n\n# plot first order integrated series\nfirst_order_int = original.diff().dropna()\naxes[1,0].plot(first_order_int)\naxes[1,0].set_title(\"First order integrated\")\nplot_acf(first_order_int, ax=axes[1,1])\nplot_pacf(first_order_int, ax=axes[1,2])\n\n# plot first order integrated series\nsecond_order_int = first_order_int.diff().dropna()\naxes[2,0].plot(first_order_int)\naxes[2,0].set_title(\"Second order integrated\");\nplot_acf(second_order_int, ax=axes[2,1])\nplot_pacf(second_order_int, ax=axes[2,2])\n\nfig.savefig('figs/acf_pacf.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit an ARIMA model to the registered rides\nfrom pmdarima import auto_arima\n\nmodel = auto_arima(registered, start_p=1, start_q=1, max_p=3, max_q=3, information_criterion=\"aic\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.summary())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot original and predicted values\nplot_data = pd.DataFrame(registered)\nplot_data['predicted'] = model.predict_in_sample()\nplot_data.plot(figsize=(12, 8))\nplt.ylabel(\"number of registered rides\")\nplt.title(\"Predicted vs actual number of rides\")\nplt.savefig('figs/registered_arima_fit.png', format='png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}